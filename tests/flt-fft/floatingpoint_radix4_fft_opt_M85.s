        .syntax unified
        .type   floatingpoint_radix4_fft_opt_M85, %function
        .global floatingpoint_radix4_fft_opt_M85


        inA .req r0
        pW0 .req r1 // Use the same twiddle data for TESTING ONLY
        sz  .req r2

        inB .req r3
        inC .req r4
        inD .req r5

        pW1 .req r6
        pW2 .req r7
        pW3 .req r8

        // NOTE:
        // We deliberately leave some aliases undefined
        // SLOTHY will fill them in as part of a 'dry-run'
        // merely concretizing symbolic registers, but not
        // yet reordering.

        .text
        .align 4
floatingpoint_radix4_fft_opt_M85:
        push    {r4-r12,lr}
        vpush   {d0-d15}

        add     inB, inA, sz
        add     inC, inB, sz
        add     inD, inC, sz

        add     pW1, pW0, sz
        add     pW2, pW1, sz
        add     pW3, pW2, sz

        lsr     lr, sz, #4
        wls     lr, lr, end

.macro load_data
        vldrw.32   qA, [inA]
        vldrw.32   qB, [inB]
        vldrw.32   qC, [inC]
        vldrw.32   qD, [inD]
.endm

.macro load_twiddles
        vldrw.s32  qTw1, [pW1], #16
        vldrw.s32  qTw2, [pW2], #16
        vldrw.s32  qTw3, [pW3], #16
.endm

.macro store_data
        vstrw.32   qA, [inA], #16
        vstrw.32   qB, [inB], #16
        vstrw.32   qC, [inC], #16
        vstrw.32   qD, [inD], #16
.endm

.macro cmul_flt out, in0, in1
        vcmul.f32  \out, \in0, \in1, #0
        vcmla.f32  \out, \in0, \in1, #270
.endm

        vldrw.32 q5, [r5]          // *.
        // gap                     // ..
        vldrw.32 q6, [r3]          // .*
        
        // original source code
        // vldrw.32 q5, [r5]      // *. 
        // vldrw.32 q6, [r3]      // .* 
        
        sub lr, lr, #1
.p2align 2
flt_radix4_fft_loop_start:
        vsub.f32 q4, q6, q5                // ..........*..............
        vldrw.32 q1, [r0]                  // *........................
        vadd.f32 q0, q6, q5                // ........*................
        vldrw.32 q6, [r4]                  // ..*......................
        vsub.f32 q3, q1, q6                // .........*...............
        vldrw.s32 q7, [r8] , #16           // ......*..................
        vcadd.f32 q2, q3, q4, #90          // ..............*..........
        // gap                             // .........................
        vcadd.f32 q5, q3, q4, #270         // .............*...........
        vcmul.f32 q3, q7, q2, #0           // ...................*.....
        vadd.f32 q6, q1, q6                // .......*.................
        vldrw.s32 q1, [r6] , #16           // ....*....................
        vcmla.f32 q3, q7, q2, #270         // ....................*....
        vldrw.s32 q7, [r7] , #16           // .....*...................
        vstrw.u32 q3, [r5] , #16           // ........................*
        // gap                             // .........................
        vsub.f32 q2, q6, q0                // ............*............
        vcmul.f32 q3, q7, q5, #0           // .................*.......
        vadd.f32 q6, q6, q0                // ...........*.............
        vcmul.f32 q0, q1, q2, #0           // ...............*.........
        vstrw.u32 q6, [r0] , #16           // .....................*...
        vcmla.f32 q3, q7, q5, #270         // ..................*......
        vldrw.32 q5, [r5]                  // ...e.....................
        vcmla.f32 q0, q1, q2, #270         // ................*........
        vstrw.u32 q3, [r4] , #16           // .......................*.
        vldrw.32 q6, [r3, #16]             // .e.......................
        vstrw.u32 q0, [r3] , #16           // ......................*..
        
        // original source code
        // vldrw.32   qA, [r0]                   // .....|*....................... 
        // vldrw.32   qB, [r3]                   // ...e.|......................e. 
        // vldrw.32   qC, [r4]                   // .....|..*..................... 
        // vldrw.32   qD, [r5]                   // e....|...................e.... 
        // vldrw.s32  qTw1, [r6], #16            // .....|.........*.............. 
        // vldrw.s32  qTw2, [r7], #16            // .....|...........*............ 
        // vldrw.s32  qTw3, [r8], #16            // .....|....*................... 
        // vadd.f32  qSm0,  qA,   qC             // .....|........*............... 
        // vadd.f32  qSm1,  qB,   qD             // .....|.*...................... 
        // vsub.f32  qDf0, qA,   qC              // .....|...*.................... 
        // vsub.f32  qDf1, qB,   qD              // .....*........................ 
        // vadd.f32  qA,   qSm0,  qSm1           // .....|...............*........ 
        // vsub.f32  qBp,  qSm0,  qSm1           // .....|.............*.......... 
        // vcadd.f32 qCp,  qDf0, qDf1, #270      // .....|......*................. 
        // vcadd.f32 qDp,  qDf0, qDf1, #90       // .....|.....*.................. 
        // vcmul.f32  qB, qTw1, qBp, #0          // .....|................*....... 
        // vcmla.f32  qB, qTw1, qBp, #270        // .*...|....................*... 
        // vcmul.f32  qC, qTw2, qCp, #0          // .....|..............*......... 
        // vcmla.f32  qC, qTw2, qCp, #270        // .....|..................*..... 
        // vcmul.f32  qD, qTw3, qDp, #0          // .....|.......*................ 
        // vcmla.f32  qD, qTw3, qDp, #270        // .....|..........*............. 
        // vstrw.32   qA, [r0], #16              // .....|.................*...... 
        // vstrw.32   qB, [r3], #16              // ....*|.......................* 
        // vstrw.32   qC, [r4], #16              // ..*..|.....................*.. 
        // vstrw.32   qD, [r5], #16              // .....|............*........... 
        
        le lr, flt_radix4_fft_loop_start
        vadd.f32 q7, q6, q5                // ..*....................
        vldrw.32 q0, [r0]                  // .*.....................
        vsub.f32 q3, q6, q5                // *......................
        vldrw.32 q2, [r4]                  // ...*...................
        vsub.f32 q1, q0, q2                // ....*..................
        vldrw.s32 q4, [r7] , #16           // ............*..........
        vcadd.f32 q5, q1, q3, #270         // .......*...............
        // gap                             // .......................
        vcadd.f32 q6, q1, q3, #90          // ......*................
        vcmul.f32 q3, q4, q5, #0           // ...............*.......
        vadd.f32 q1, q0, q2                // .........*.............
        vldrw.s32 q2, [r8] , #16           // .....*.................
        vcmla.f32 q3, q4, q5, #270         // ...................*...
        vldrw.s32 q4, [r6] , #16           // ..........*............
        vstrw.u32 q3, [r4] , #16           // .....................*.
        // gap                             // .......................
        vsub.f32 q5, q1, q7                // ..............*........
        vcmul.f32 q0, q2, q6, #0           // ........*..............
        vadd.f32 q3, q1, q7                // ................*......
        vcmul.f32 q1, q4, q5, #0           // .................*.....
        vstrw.u32 q3, [r0] , #16           // ..................*....
        vcmla.f32 q0, q2, q6, #270         // ...........*...........
        // gap                             // .......................
        vstrw.u32 q0, [r5] , #16           // .............*.........
        vcmla.f32 q1, q4, q5, #270         // ....................*..
        // gap                             // .......................
        vstrw.u32 q1, [r3] , #16           // ......................*
        
        // original source code
        // vsub.f32 q4, q6, q5             // ..*.................... 
        // vldrw.32 q1, [r0]               // .*..................... 
        // vadd.f32 q0, q6, q5             // *...................... 
        // vldrw.32 q6, [r4]               // ...*................... 
        // vsub.f32 q3, q1, q6             // ....*.................. 
        // vldrw.s32 q7, [r8] , #16        // ..........*............ 
        // vcadd.f32 q2, q3, q4, #90       // .......*............... 
        // vcadd.f32 q5, q3, q4, #270      // ......*................ 
        // vcmul.f32 q3, q7, q2, #0        // ...............*....... 
        // vadd.f32 q6, q1, q6             // .........*............. 
        // vldrw.s32 q1, [r6] , #16        // ............*.......... 
        // vcmla.f32 q3, q7, q2, #270      // ...................*... 
        // vldrw.s32 q7, [r7] , #16        // .....*................. 
        // vstrw.u32 q3, [r5] , #16        // ....................*.. 
        // vsub.f32 q2, q6, q0             // ..............*........ 
        // vcmul.f32 q3, q7, q5, #0        // ........*.............. 
        // vadd.f32 q6, q6, q0             // ................*...... 
        // vcmul.f32 q0, q1, q2, #0        // .................*..... 
        // vstrw.u32 q6, [r0] , #16        // ..................*.... 
        // vcmla.f32 q3, q7, q5, #270      // ...........*........... 
        // vcmla.f32 q0, q1, q2, #270      // .....................*. 
        // vstrw.u32 q3, [r4] , #16        // .............*......... 
        // vstrw.u32 q0, [r3] , #16        // ......................* 
        

end:
        vpop    {d0-d15}
        pop     {r4-r12,lr}
        bx      lr